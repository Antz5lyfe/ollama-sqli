import getpass
import os
from typing import TypedDict
import warnings
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from pydantic import BaseModel, Field
from langgraph_supervisor import create_supervisor
from langchain.chat_models import init_chat_model
from langgraph.graph import StateGraph, MessagesState, START, END
from langchain_core.messages import HumanMessage, AIMessage
from pytz import all_timezones_set
from mcp_client import get_mcp_tools
import asyncio
from langchain_community.utilities import GoogleSerperAPIWrapper
from langchain_core.tools import Tool
import sqlite3
from langgraph.checkpoint.sqlite import SqliteSaver
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langgraph.prebuilt.chat_agent_executor import (
    AgentStateWithStructuredResponse,
    AgentState,
)


class AgentOutput(TypedDict):
    """Final output of the Agent"""

    final_output: list[dict[str, str]] = Field(
        description="The exact final json output of the Agent"
    )


class agent2State(AgentState):
    final: list[dict[str, str]]


load_dotenv()

prompt = ChatPromptTemplate(
    [
        (
            "system",
            """
Generate a list of simple math questions and their answers. Response in JSON format like this:
```json
[
    {{
        "question": "<question>",
        "answer": "<answer>",
        "explanation": "<why the answer is correct>"
    }},
    ...
]
    """,
        ),
        ("placeholder", "{messages}"),
    ]
)

prompt2 = ChatPromptTemplate(
    [
        (
            "system",
            """
            Here is a list of questions and answers: {final}
            Return a list of all questions only.
    """,
        ),
        ("placeholder", "{messages}"),
    ]
)


agent = create_react_agent(
    model="openai:gpt-4.1-mini",
    prompt=prompt,
    response_format=("Copy the exact final output", AgentOutput),
    name="random_question_generator",
    tools=[],
)

resp = agent.invoke({"messages": []})
print(resp["messages"][-1], resp["structured_response"])

agent2 = create_react_agent(
    model="openai:gpt-4.1-mini",
    prompt=prompt2,
    name="question_extractor",
    state_schema=agent2State,
    tools=[],
)

# run = prompt2 | ChatOpenAI(model="openai:gpt-4.1-mini")

# print(
#     run.invoke({"final": resp["structured_response"]["final_output"]})["messages"][
#         -1
#     ].content
# )
resp2 = agent2.invoke(
    {"messages": [], "final": resp["structured_response"]["final_output"]}
)

print(resp2["messages"][-1].content)
